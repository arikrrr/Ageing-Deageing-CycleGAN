{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import itertools\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, mode='train'):\n",
    "        self.transform = transforms_\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, '%sA' % mode) + '/*.*'))\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, '%sB' % mode) + '/*.*'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n",
    "        item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n",
    "\n",
    "        return {'A': item_A, 'B': item_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if np.random.uniform(0, 1) > 0.5:\n",
    "                    i = np.random.randint(0, self.max_size)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)\n",
    "\n",
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, input_shape, num_residual_blocks):\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.num_residual_blocks = num_residual_blocks\n",
    "\n",
    "        # Initial convolution block\n",
    "        model = [nn.Conv2d(input_shape[0], 64, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "                 nn.InstanceNorm2d(64),\n",
    "                 nn.ReLU(inplace=True)]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                      nn.InstanceNorm2d(out_features),\n",
    "                      nn.ReLU(inplace=True)]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(num_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n",
    "                      nn.InstanceNorm2d(out_features),\n",
    "                      nn.ReLU(inplace=True)]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        # Output layer\n",
    "        model += [nn.Conv2d(64, input_shape[0], kernel_size=7, stride=1, padding=3),\n",
    "                  nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                      nn.InstanceNorm2d(in_features),\n",
    "                      nn.ReLU(inplace=True),\n",
    "                      nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                      nn.InstanceNorm2d(in_features)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        in_channels, height, width = self.input_shape\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, kernel_size=4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels, 64, normalize=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "\n",
    "class CycleGAN():\n",
    "    def __init__(self, dataset_name='dataset_preprocessed', img_height=100, img_width=100, channels=3, lr=0.0002, b1=0.5, b2=0.999):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.channels = channels\n",
    "        self.input_shape = (self.channels, self.img_height, self.img_width)\n",
    "\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        # Initialize the generator and discriminator\n",
    "        self.G_AB = GeneratorResNet(self.input_shape, num_residual_blocks=9).to(self.device)\n",
    "        self.G_BA = GeneratorResNet(self.input_shape, num_residual_blocks=9).to(self.device)\n",
    "        self.D_A = Discriminator(self.input_shape).to(self.device)\n",
    "        self.D_B = Discriminator(self.input_shape).to(self.device)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.G_AB.apply(self.weights_init_normal)\n",
    "        self.G_BA.apply(self.weights_init_normal)\n",
    "        self.D_A.apply(self.weights_init_normal)\n",
    "        self.D_B.apply(self.weights_init_normal)\n",
    "\n",
    "        # Losses\n",
    "        self.criterion_GAN = torch.nn.MSELoss().to(self.device)\n",
    "        self.criterion_cycle = torch.nn.L1Loss().to(self.device)\n",
    "        self.criterion_identity = torch.nn.L1Loss().to(self.device)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer_G = torch.optim.Adam(\n",
    "            itertools.chain(self.G_AB.parameters(), self.G_BA.parameters()), lr=lr, betas=(b1, b2))\n",
    "        self.optimizer_D_A = torch.optim.Adam(self.D_A.parameters(), lr=lr, betas=(b1, b2))\n",
    "        self.optimizer_D_B = torch.optim.Adam(self.D_B.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "        # Buffers of previously generated samples\n",
    "        self.fake_A_buffer = ReplayBuffer()\n",
    "        self.fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "        # Image transformations\n",
    "        self.transforms_ = transforms.Compose([\n",
    "            transforms.Resize(int(self.img_height * 1.12), Image.BICUBIC),\n",
    "            transforms.RandomCrop((self.img_height, self.img_width)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def weights_init_normal(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50, saving_dir='saved_models'):\n",
    "        # Load dataset\n",
    "        dataloader = DataLoader(ImageDataset(f'./{self.dataset_name}', transforms_=self.transforms_),\n",
    "                                batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "        # Test the output size of the Discriminator\n",
    "        sample_input = torch.randn((batch_size, *self.input_shape)).to(self.device)\n",
    "        output_size = self.D_A(sample_input).shape[2:]\n",
    "        valid = torch.ones((batch_size, 1, *output_size), requires_grad=False).to(self.device)\n",
    "        fake = torch.zeros((batch_size, 1, *output_size), requires_grad=False).to(self.device)\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Set model input\n",
    "                real_A = batch['A'].to(self.device)\n",
    "                real_B = batch['B'].to(self.device)\n",
    "\n",
    "                # ----------------------\n",
    "                #  Train Generators\n",
    "                # ----------------------\n",
    "\n",
    "                self.optimizer_G.zero_grad()\n",
    "\n",
    "                # Identity loss\n",
    "                loss_id_A = self.criterion_identity(self.G_BA(real_A), real_A)\n",
    "                loss_id_B = self.criterion_identity(self.G_AB(real_B), real_B)\n",
    "\n",
    "                loss_identity = (loss_id_A + loss_id_B) / 2\n",
    "\n",
    "                # GAN loss\n",
    "                fake_B = self.G_AB(real_A)\n",
    "                loss_GAN_AB = self.criterion_GAN(self.D_B(fake_B), valid)\n",
    "                fake_A = self.G_BA(real_B)\n",
    "                loss_GAN_BA = self.criterion_GAN(self.D_A(fake_A), valid)\n",
    "\n",
    "                loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
    "\n",
    "                # Cycle loss\n",
    "                recov_A = self.G_BA(fake_B)\n",
    "                loss_cycle_A = self.criterion_cycle(recov_A, real_A)\n",
    "                recov_B = self.G_AB(fake_A)\n",
    "                loss_cycle_B = self.criterion_cycle(recov_B, real_B)\n",
    "\n",
    "                loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
    "\n",
    "                # Total loss\n",
    "                loss_G = loss_GAN + 10.0 * loss_cycle + 5.0 * loss_identity\n",
    "\n",
    "                loss_G.backward()\n",
    "                self.optimizer_G.step()\n",
    "\n",
    "                # -----------------------\n",
    "                #  Train Discriminator A\n",
    "                # -----------------------\n",
    "\n",
    "                self.optimizer_D_A.zero_grad()\n",
    "\n",
    "                # Real loss\n",
    "                loss_real = self.criterion_GAN(self.D_A(real_A), valid)\n",
    "                # Fake loss (on batch of previously generated samples)\n",
    "                fake_A_ = self.fake_A_buffer.push_and_pop(fake_A)\n",
    "                loss_fake = self.criterion_GAN(self.D_A(fake_A_.detach()), fake)\n",
    "\n",
    "                # Total loss\n",
    "                loss_D_A = (loss_real + loss_fake) / 2\n",
    "\n",
    "                loss_D_A.backward()\n",
    "                self.optimizer_D_A.step()\n",
    "\n",
    "                # -----------------------\n",
    "                #  Train Discriminator B\n",
    "                # -----------------------\n",
    "\n",
    "                self.optimizer_D_B.zero_grad()\n",
    "\n",
    "                # Real loss\n",
    "                loss_real = self.criterion_GAN(self.D_B(real_B), valid)\n",
    "                # Fake loss (on batch of previously generated samples)\n",
    "                fake_B_ = self.fake_B_buffer.push_and_pop(fake_B)\n",
    "                loss_fake = self.criterion_GAN(self.D_B(fake_B_.detach()), fake)\n",
    "\n",
    "                # Total loss\n",
    "                loss_D_B = (loss_real + loss_fake) / 2\n",
    "\n",
    "                loss_D_B.backward()\n",
    "                self.optimizer_D_B.step()\n",
    "\n",
    "                loss_D = (loss_D_A + loss_D_B) / 2\n",
    "\n",
    "                # --------------\n",
    "                #  Log Progress\n",
    "                # --------------\n",
    "\n",
    "                batches_done = epoch * len(dataloader) + i\n",
    "                batches_left = epochs * len(dataloader) - batches_done\n",
    "                time_left = datetime.timedelta(seconds=batches_left * (datetime.datetime.now() - start_time).seconds / max(1, batches_done))\n",
    "\n",
    "                print(f'\\r[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {loss_D.item()}] [G loss: {loss_G.item()}] '\n",
    "                      f'[Adv: {loss_GAN.item()}] [Cycle: {loss_cycle.item()}] [Identity: {loss_identity.item()}] ETA: {time_left}', end='')\n",
    "\n",
    "                # If at sample interval save image\n",
    "                if batches_done % sample_interval == 0:\n",
    "                    self.sample_images(batches_done, epoch)\n",
    "\n",
    "            # Save model checkpoints\n",
    "            if epoch % 2 == 0:\n",
    "                os.makedirs(saving_dir, exist_ok=True)\n",
    "                torch.save(self.G_AB.state_dict(), os.path.join(saving_dir, f'G_AB_{epoch}.pth'))\n",
    "                torch.save(self.G_BA.state_dict(), os.path.join(saving_dir, f'G_BA_{epoch}.pth'))\n",
    "                torch.save(self.D_A.state_dict(), os.path.join(saving_dir, f'D_A_{epoch}.pth'))\n",
    "                torch.save(self.D_B.state_dict(), os.path.join(saving_dir, f'D_B_{epoch}.pth'))\n",
    "\n",
    "    def sample_images(self, batches_done, epoch):\n",
    "        os.makedirs('images/%s/%s' % (self.dataset_name, epoch), exist_ok=True)\n",
    "        imgs = next(iter(DataLoader(ImageDataset(f'./{self.dataset_name}', transforms_=self.transforms_, mode='train'), batch_size=5, shuffle=True)))\n",
    "        real_A = imgs['A'].to(self.device)\n",
    "        real_B = imgs['B'].to(self.device)\n",
    "        fake_B = self.G_AB(real_A)\n",
    "        fake_A = self.G_BA(real_B)\n",
    "        recov_A = self.G_BA(fake_B)\n",
    "        recov_B = self.G_AB(fake_A)\n",
    "        img_sample = torch.cat((real_A.data, fake_B.data, recov_A.data, real_B.data, fake_A.data, recov_B.data), 0)\n",
    "        save_image(img_sample, 'images/%s/%s/%s.png' % (self.dataset_name, epoch, batches_done), nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CycleGAN instance and start training\n",
    "cyclegan = CycleGAN()\n",
    "cyclegan.train(epochs=200, batch_size=1, sample_interval=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchMl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
